{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextClassification_ML&spacy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "THQgsd2V56sH",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "50e23751-4763-4808-e3c7-bc5caa93770c"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-48152b19-5fd9-407a-8b07-efdb552e8877\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-48152b19-5fd9-407a-8b07-efdb552e8877\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving amazon_cells_labelled.txt to amazon_cells_labelled.txt\n",
            "Saving imdb_labelled.txt to imdb_labelled.txt\n",
            "Saving yelp_labelled.txt to yelp_labelled.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU4BqhbJCrWK"
      },
      "source": [
        "Aim is to classify reviews into positive or negative review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2owVSy6PCX1E"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHWUZYFtCp-R"
      },
      "source": [
        "df_yelp = pd.read_table(\"yelp_labelled.txt\")\n",
        "df_imdb = pd.read_table(\"imdb_labelled.txt\")\n",
        "df_amz = pd.read_table(\"amazon_cells_labelled.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJnRMlOADBTs",
        "outputId": "69a991f2-dc7c-4cd9-bc8d-7efad8b5828a"
      },
      "source": [
        "frames = [df_yelp,df_imdb,df_amz]\n",
        "print(frames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[                              Wow... Loved this place.  1\n",
            "0                                   Crust is not good.  0\n",
            "1            Not tasty and the texture was just nasty.  0\n",
            "2    Stopped by during the late May bank holiday of...  1\n",
            "3    The selection on the menu was great and so wer...  1\n",
            "4       Now I am getting angry and I want my damn pho.  0\n",
            "..                                                 ... ..\n",
            "994  I think food should have flavor and texture an...  0\n",
            "995                           Appetite instantly gone.  0\n",
            "996  Overall I was not impressed and would not go b...  0\n",
            "997  The whole experience was underwhelming, and I ...  0\n",
            "998  Then, as if I hadn't wasted enough of my life ...  0\n",
            "\n",
            "[999 rows x 2 columns],     A very, very, very slow-moving, aimless movie about a distressed, drifting young man.    0\n",
            "0    Not sure who was more lost - the flat characte...                                       0\n",
            "1    Attempting artiness with black & white and cle...                                       0\n",
            "2         Very little music or anything to speak of.                                         0\n",
            "3    The best scene in the movie was when Gerardo i...                                       1\n",
            "4    The rest of the movie lacks art, charm, meanin...                                       0\n",
            "..                                                 ...                                      ..\n",
            "742  I just got bored watching Jessice Lange take h...                                       0\n",
            "743  Unfortunately, any virtue in this film's produ...                                       0\n",
            "744                   In a word, it is embarrassing.                                         0\n",
            "745                               Exceptionally bad!                                         0\n",
            "746  All in all its an insult to one's intelligence...                                       0\n",
            "\n",
            "[747 rows x 2 columns],     So there is no way for me to plug it in here in the US unless I go by a converter.  0\n",
            "0                          Good case, Excellent value.                                  1\n",
            "1                               Great for the jawbone.                                  1\n",
            "2    Tied to charger for conversations lasting more...                                  0\n",
            "3                                    The mic is great.                                  1\n",
            "4    I have to jiggle the plug to get it to line up...                                  0\n",
            "..                                                 ...                                 ..\n",
            "994  The screen does get smudged easily because it ...                                  0\n",
            "995  What a piece of junk.. I lose more calls on th...                                  0\n",
            "996                       Item Does Not Match Picture.                                  0\n",
            "997  The only thing that disappoint me is the infra...                                  0\n",
            "998  You can not answer calls with the unit, never ...                                  0\n",
            "\n",
            "[999 rows x 2 columns]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtydLA3sDbQo",
        "outputId": "6f77feb7-df30-44f0-c02a-181935776e72"
      },
      "source": [
        "for colname in frames:\n",
        "  colname.columns = ['Message','Target']\n",
        "for colname in frames:\n",
        "  print(colname.columns)\n",
        "print(frames[0].iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Message', 'Target'], dtype='object')\n",
            "Index(['Message', 'Target'], dtype='object')\n",
            "Index(['Message', 'Target'], dtype='object')\n",
            "Message    Crust is not good.\n",
            "Target                      0\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HJ4lW-yEa1F",
        "outputId": "5c7f7e20-b56d-457b-fa8b-346be5062e5a"
      },
      "source": [
        "keys = ['Yelp','IMDB','Amazon']\n",
        "print(keys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Yelp', 'IMDB', 'Amazon']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kx3LgL4FIEj",
        "outputId": "6b975edc-001f-4084-a667-ce3b8658f088"
      },
      "source": [
        "print(df.shape)\n",
        "df = pd.concat(frames,keys=keys)\n",
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2745, 2)\n",
            "                                                  Message  Target\n",
            "Yelp 0                                 Crust is not good.       0\n",
            "     1          Not tasty and the texture was just nasty.       0\n",
            "     2  Stopped by during the late May bank holiday of...       1\n",
            "     3  The selection on the menu was great and so wer...       1\n",
            "     4     Now I am getting angry and I want my damn pho.       0\n",
            "(2745, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKVMHNMeFrvn",
        "outputId": "6ed9e3e2-8bc3-49eb-b99f-69f42329944a"
      },
      "source": [
        "df.to_csv(\"sentimentdataset_from3dataset.csv\")\n",
        "#files.download(\"sentimentdataset_from3dataset.csv\")\n",
        "df.columns\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Message    0\n",
              "Target     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGlGxzxOIrya"
      },
      "source": [
        "\n",
        "Working with SpaCy\n",
        "\n",
        "    Removing Stopwords\n",
        "    Lemmatizing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFUkaGXwH-j5"
      },
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w8KLVw_hih_",
        "outputId": "83c6837c-0e27-4616-ab86-ffede64643d1"
      },
      "source": [
        "stopwords = list(STOP_WORDS)\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['after', 'become', 'full', 'ours', 'seems', 'it', 'whereby', 'out', 'anyone', 'or', 'empty', 'anyhow', 'whereafter', 'do', \"n't\", 'me', 'though', 'someone', 'is', 'does', 'seeming', 'fifty', 'nowhere', 'amount', 'such', 'twelve', 'against', 'least', 'of', 'who', 'go', 'in', 'whatever', 'alone', 'if', 'what', 'much', 'mine', 'not', 'being', 'next', 'still', 'five', 'say', 'us', 'thus', 'something', 'latter', 'off', 'besides', 'could', 'few', 'neither', 'those', 'am', 'among', 'two', 'move', 'was', 'hereupon', 'until', 'mostly', 'wherever', 'indeed', 'had', 'have', 'myself', 'several', 'themselves', 'ca', 'whole', 'are', 'enough', 'third', 'its', 'he', 'latterly', 'ten', 'hers', 'front', 'both', 'nobody', 'been', 'almost', 'every', 'yourselves', 'did', 'whereas', 'noone', 'ourselves', 'that', 'more', 'whoever', 'into', 'back', 'between', 'became', 'moreover', 'for', 'everywhere', 'part', 'below', 'quite', 'see', 'too', '‘s', 'again', 'be', 'other', 'otherwise', 'as', 'everything', 'through', 'already', 'her', 'four', 'were', \"'d\", 'six', 'all', 'show', 'may', 'afterwards', 'unless', 'some', 'many', 'using', 'former', 'last', 'sixty', 'these', 'since', 'hereafter', 'this', 'over', 'to', \"'s\", 'before', 'himself', 'made', 'up', 'none', 'very', 'with', 'has', 'done', 'make', 'must', 'from', 'wherein', 'whether', 'which', 'only', 'somehow', 'whom', 'yours', 'where', 'his', 'three', 'however', 'we', 'upon', 'their', 'namely', 'less', 'hence', 'give', 'can', 'elsewhere', 'per', '’d', 'each', 'i', 'along', 'itself', 'thence', 'various', 'whose', 'she', 'so', 'anywhere', 'call', 'eleven', 'him', 'formerly', 'always', 'please', 'sometime', 'forty', 'there', 'now', 'our', '’re', 'most', '‘ve', 'any', 'fifteen', 'serious', 'nothing', 'under', 'others', 'due', 'than', 'another', 'anyway', 'well', 'whenever', \"'ve\", 'else', 'also', 'everyone', 'perhaps', 'used', 'nor', \"'ll\", 'my', 'thereafter', 'top', 'throughout', 'about', 'when', 'rather', 'around', 'by', 'really', 'down', 'during', 'thereby', '‘d', 'behind', 'beforehand', 'beside', 'nine', 'regarding', 'one', \"'re\", 'then', 'towards', 'might', 'just', 'bottom', 'same', 'even', 'sometimes', 'cannot', 'whence', 'the', 'often', 'n‘t', 'eight', 'across', 're', 'yet', 'them', 'doing', 'no', 'anything', 'side', 'seem', 'seemed', 'together', 'twenty', '’ll', 'take', 'while', 'without', 'a', 'would', 'hundred', 'therefore', '‘ll', 'therein', 'herein', 'own', 'but', 'hereby', 'amongst', \"'m\", 'name', 'whither', '’s', 'becoming', 'above', 'first', 'will', 'within', 'keep', 'although', 'becomes', 'and', 'meanwhile', 'beyond', 'never', 'nevertheless', 'once', 'put', '‘m', '‘re', 'because', 'here', 'toward', '’ve', 'either', 'on', 'you', 'onto', 'except', 'via', 'thereupon', 'should', '’m', 'yourself', 'they', 'an', 'your', 'further', 'at', 'thru', 'whereupon', 'n’t', 'somewhere', 'why', 'how', 'ever', 'herself', 'get']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBouSekghpPG"
      },
      "source": [
        "docx = nlp(\"This is how John Walker was walking. He was also running beside the lawn.\")\n",
        "#nlp - to process the text -> split into individual words and annotated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctOSbkNKiYeP",
        "outputId": "d2ab7676-829b-49b7-af3b-ce33a9ce1e05"
      },
      "source": [
        "for word in docx:\n",
        "  print(word.text,\"lemma ->\",word.lemma_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This lemma -> this\n",
            "is lemma -> be\n",
            "how lemma -> how\n",
            "John lemma -> John\n",
            "Walker lemma -> Walker\n",
            "was lemma -> be\n",
            "walking lemma -> walk\n",
            ". lemma -> .\n",
            "He lemma -> -PRON-\n",
            "was lemma -> be\n",
            "also lemma -> also\n",
            "running lemma -> run\n",
            "beside lemma -> beside\n",
            "the lemma -> the\n",
            "lawn lemma -> lawn\n",
            ". lemma -> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyTSohOuii27",
        "outputId": "efab9452-78ad-4b51-d50b-fb598b017763"
      },
      "source": [
        "#filtering not pronun lemma\n",
        "for word in docx:\n",
        "  if word.lemma_ != '-PRON-':\n",
        "    print(word.lemma_.lower().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this\n",
            "be\n",
            "how\n",
            "john\n",
            "walker\n",
            "be\n",
            "walk\n",
            ".\n",
            "be\n",
            "also\n",
            "run\n",
            "beside\n",
            "the\n",
            "lawn\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TQgODASpnT2",
        "outputId": "ffe0e273-58d1-4585-fe8f-876823edd643"
      },
      "source": [
        "#list comprehension for lemma\n",
        "lemmawords=[word.lemma_.lower().strip() if word.lemma_ != '-PRON-' else word.lower_ for word in docx]\n",
        "print(lemmawords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'be', 'how', 'john', 'walker', 'be', 'walk', '.', 'be', 'also', 'run', 'beside', 'the', 'lawn', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdwIsvoTwja5",
        "outputId": "bdcaee9a-8fea-451e-91db-9ccc7197d3be"
      },
      "source": [
        "#filtering stop words and punct\n",
        "for word in docx:\n",
        "  if word.is_stop == False and not word.is_punct:\n",
        "    print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "John\n",
            "Walker\n",
            "walking\n",
            "running\n",
            "lawn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDZl1YSRzAf6",
        "outputId": "42ab0b00-50cb-40c4-ec8f-ac15b1faa77c"
      },
      "source": [
        "[ word for word in docx if word.is_stop == False and not word.is_punct]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[John, Walker, walking, running, lawn]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akgXX3W80imX"
      },
      "source": [
        "above lemma, stopwords and punct are to learn.. you an write a funct to take only words which is not a stopword and punct and it in lemma form.....use the funct below for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZCQ8sngzxfm"
      },
      "source": [
        "import string\n",
        "punctuations = string.punctuation\n",
        "from spacy.lang.en import English\n",
        "parser = English()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRMvC-zY0_RP"
      },
      "source": [
        "def spacy_tokenizer(sentence):\n",
        "  mytokens = parser(sentence)\n",
        "  mytokens = [word.lemma_.lower().strip() if word.lemma_ != '-PRON-' else word.lower_ for word in docx]\n",
        "  mytokens = [ word for word in docx if word.is_stop == False and not word.is_punct] \n",
        "    # [ word for word in docx if word not in stopwords and word not in punctuations]\n",
        "  return mytokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCLFeaxe1xh7"
      },
      "source": [
        "Machine learning with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXm01esI1iTR"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.base import TransformerMixin \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz5x40L1ILWt"
      },
      "source": [
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [clean_text(text) for text in X]\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "# Basic function to clean the text \n",
        "def clean_text(text):     \n",
        "    return text.strip().lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnBQOQu0Ig3I"
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1)) \n",
        "classifier1 = LinearSVC()\n",
        "classifier2 = RandomForestClassifier()\n",
        "tfvectorizer = TfidfVectorizer(tokenizer = spacy_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OItcdaHaIo9m"
      },
      "source": [
        "X = df['Message']\n",
        "y = df['Target']\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqCZ_kwoKAer"
      },
      "source": [
        "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
        "pipe1 = Pipeline([(\"cleaner1\", predictors()),\n",
        "                 ('vectorizer1', vectorizer),\n",
        "                 ('classifier1', classifier1)])\n",
        "pipe2 = Pipeline([(\"cleaner2\", predictors()),\n",
        "                 ('vectorizer2', vectorizer),\n",
        "                 ('classifier2', classifier2)])\n",
        "pipe3 = Pipeline([(\"cleaner3\", predictors()),\n",
        "                 ('tfvectorizer1', tfvectorizer),\n",
        "                 ('classifier3', classifier1)])\n",
        "pipe4 = Pipeline([(\"cleaner4\", predictors()),\n",
        "                 ('tfvectorizer2', tfvectorizer),\n",
        "                 ('classifier4', classifier2)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Dh_3VHKJuj"
      },
      "source": [
        "pipeline = [pipe1,pipe2,pipe3,pipe4]\n",
        "for pipe in pipeline:\n",
        "  pipe.fit(x_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAJBfB-_M61c",
        "outputId": "038a3bbe-4ec6-4a0d-c61a-f0e019f602c8"
      },
      "source": [
        "pipe_dict = {0:'pipe1',1:'pipe2',2:'pipe3',3:'pipe4'}\n",
        "#test accuracy\n",
        "for i,model in enumerate(pipeline):\n",
        "  #print(\"{} test acc is {}\".format(pipe_dict[i],model.score(x_test,y_test)))\n",
        "  print(\" \",pipe_dict[i],\" test acc is \",model.score(x_test,y_test)) # use any print"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  pipe1  test acc is  0.47815533980582525\n",
            "  pipe2  test acc is  0.47815533980582525\n",
            "  pipe3  test acc is  0.47815533980582525\n",
            "  pipe4  test acc is  0.47815533980582525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kezZLWkTOBFy",
        "outputId": "06578d8b-6d88-4a3d-e984-f4a283ed4f6f"
      },
      "source": [
        "bestacc = 0.0\n",
        "bestpipe =\"\"\n",
        "for i,model in enumerate(pipeline):\n",
        "  if model.score(x_test,y_test) > bestacc:\n",
        "    bestacc = model.score(x_test,y_test)\n",
        "    bestpipe = i\n",
        "print(\"best pipe is \",pipe_dict[bestpipe],\"with test_acc\",bestacc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best pipe is  pipe1 with test_acc 0.47815533980582525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xknJHSXKVJC"
      },
      "source": [
        "forecast = pipe1.predict(x_test)\n",
        "# Prediction Results\n",
        "# 1 = Positive review\n",
        "# 0 = Negative review\n",
        "for (sample,pred) in zip(x_test,forecast):\n",
        "    print(sample,\"Prediction=>\",pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR4F1zR2KcJI",
        "outputId": "0d104cab-ac04-4455-efae-2ec676716c2f"
      },
      "source": [
        "print(\"Accuracy: \",pipe1.score(x_test,y_test))\n",
        "print(\"Accuracy: \",pipe1.score(x_test,forecast))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.47815533980582525\n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scM_bKSyK3g2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}